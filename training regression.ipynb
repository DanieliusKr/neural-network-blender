{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5ff950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor \n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5083cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindt = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756e116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassLogisticRegression(\n",
      "  (linear): Linear(in_features=100, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([T.Resize(10), T.ToTensor(),])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
    "\n",
    "class MulticlassLogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MulticlassLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(100, 10, bias=False) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 10*10)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = MulticlassLogisticRegression()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14444372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 TRAIN LOSS : 0.049429771234231715\n",
      "EPOCH 2 TRAIN LOSS : 0.040949943985766186\n",
      "EPOCH 3 TRAIN LOSS : 0.03474326631916103\n",
      "EPOCH 4 TRAIN LOSS : 0.03010570342098472\n",
      "EPOCH 5 TRAIN LOSS : 0.025859049388340542\n",
      "EPOCH 6 TRAIN LOSS : 0.023904474432280325\n",
      "EPOCH 7 TRAIN LOSS : 0.02236933634479417\n",
      "EPOCH 8 TRAIN LOSS : 0.020130833710180415\n",
      "EPOCH 9 TRAIN LOSS : 0.01887476634877577\n",
      "EPOCH 10 TRAIN LOSS : 0.018072802374866217\n",
      "EPOCH 11 TRAIN LOSS : 0.01689650064338245\n",
      "EPOCH 12 TRAIN LOSS : 0.016210855832740442\n",
      "EPOCH 13 TRAIN LOSS : 0.015215442378892064\n",
      "EPOCH 14 TRAIN LOSS : 0.014970771031084854\n",
      "EPOCH 15 TRAIN LOSS : 0.01565117495400565\n",
      "EPOCH 16 TRAIN LOSS : 0.013801419404523967\n",
      "EPOCH 17 TRAIN LOSS : 0.013834411592117504\n",
      "EPOCH 18 TRAIN LOSS : 0.013720992277425998\n",
      "EPOCH 19 TRAIN LOSS : 0.013430981303074721\n",
      "EPOCH 20 TRAIN LOSS : 0.012443502828764764\n",
      "EPOCH 21 TRAIN LOSS : 0.013017297998420212\n",
      "EPOCH 22 TRAIN LOSS : 0.012166319053564498\n",
      "EPOCH 23 TRAIN LOSS : 0.012567679765127869\n",
      "EPOCH 24 TRAIN LOSS : 0.012792565865811508\n",
      "EPOCH 25 TRAIN LOSS : 0.012180784935636053\n",
      "EPOCH 26 TRAIN LOSS : 0.012065757312245969\n",
      "EPOCH 27 TRAIN LOSS : 0.01155415444231745\n",
      "EPOCH 28 TRAIN LOSS : 0.012214525231420359\n",
      "EPOCH 29 TRAIN LOSS : 0.011312977400924098\n",
      "EPOCH 30 TRAIN LOSS : 0.010878482416494568\n",
      "EPOCH 31 TRAIN LOSS : 0.010994875608985103\n",
      "EPOCH 32 TRAIN LOSS : 0.010792328414123958\n",
      "EPOCH 33 TRAIN LOSS : 0.010756672699568369\n",
      "EPOCH 34 TRAIN LOSS : 0.01176997301166754\n",
      "EPOCH 35 TRAIN LOSS : 0.010472666670772821\n",
      "EPOCH 36 TRAIN LOSS : 0.010181860628921086\n",
      "EPOCH 37 TRAIN LOSS : 0.010448638182967457\n",
      "EPOCH 38 TRAIN LOSS : 0.010167591670937122\n",
      "EPOCH 39 TRAIN LOSS : 0.009363278905465913\n",
      "EPOCH 40 TRAIN LOSS : 0.010489696632824473\n",
      "EPOCH 41 TRAIN LOSS : 0.010121223514776494\n",
      "EPOCH 42 TRAIN LOSS : 0.009649924504985688\n",
      "EPOCH 43 TRAIN LOSS : 0.010352902829265797\n",
      "EPOCH 44 TRAIN LOSS : 0.009596067895767276\n",
      "EPOCH 45 TRAIN LOSS : 0.00933299148514835\n",
      "EPOCH 46 TRAIN LOSS : 0.010342265814860493\n",
      "EPOCH 47 TRAIN LOSS : 0.0088222202842932\n",
      "EPOCH 48 TRAIN LOSS : 0.00872150244616242\n",
      "EPOCH 49 TRAIN LOSS : 0.0093856744928909\n",
      "EPOCH 50 TRAIN LOSS : 0.0094451437245554\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    sum_losses = 0\n",
    "    for x, (images, labels) in enumerate(train_loader): \n",
    "        images = images.reshape(-1, 10*10)\n",
    "        \n",
    "        out = model(images)\n",
    "        losses = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step() \n",
    "        sum_losses += losses.item()\n",
    "        if x == 10:\n",
    "            break\n",
    "        \n",
    "    print(f\"EPOCH {epoch+1} TRAIN LOSS : {sum_losses / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6218a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "weights = model.linear.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55b39db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531fe0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (imgs, labels) in enumerate(train_loader):\n",
    "    \n",
    "    outputs = nn.Softmax(dim=1)(model(imgs))\n",
    "    imgs = imgs.detach().cpu().numpy()\n",
    "    \n",
    "    imgs2 = imgs.reshape((128, 100))\n",
    "    \n",
    "    w = (imgs2[:, np.newaxis, :] * weights[np.newaxis, :, :]).transpose(2, 1, 0)\n",
    "    w = np.maximum(w, 0)\n",
    "    w = np.minimum(w, 1)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    imgs = np.squeeze(imgs, axis=1).transpose(1, 2, 0)\n",
    "    outputs = np.expand_dims(outputs, axis=1).transpose(1, 2, 0)\n",
    "    np.save(\"inputs.npy\", imgs)\n",
    "    np.save(\"outputs.npy\", outputs)\n",
    "    np.save(\"weights.npy\", w)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d83d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
