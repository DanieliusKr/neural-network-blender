{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5ff950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor \n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5083cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindt = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756e116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassLogisticRegression(\n",
      "  (linear): Linear(in_features=100, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([T.Resize(10), T.ToTensor(),])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
    "\n",
    "class MulticlassLogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MulticlassLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(100, 10, bias=False) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 10*10)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = MulticlassLogisticRegression()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14444372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 TRAIN LOSS : 0.04927086296366222\n",
      "EPOCH 2 TRAIN LOSS : 0.040947441353218386\n",
      "EPOCH 3 TRAIN LOSS : 0.034803865052489585\n",
      "EPOCH 4 TRAIN LOSS : 0.029897562476363517\n",
      "EPOCH 5 TRAIN LOSS : 0.02601870621191159\n",
      "EPOCH 6 TRAIN LOSS : 0.02355194066379116\n",
      "EPOCH 7 TRAIN LOSS : 0.021956349740912918\n",
      "EPOCH 8 TRAIN LOSS : 0.020437889388883548\n",
      "EPOCH 9 TRAIN LOSS : 0.01926871797423373\n",
      "EPOCH 10 TRAIN LOSS : 0.018611939858271878\n",
      "EPOCH 11 TRAIN LOSS : 0.017569879478991413\n",
      "EPOCH 12 TRAIN LOSS : 0.017486985177119403\n",
      "EPOCH 13 TRAIN LOSS : 0.015547546496523469\n",
      "EPOCH 14 TRAIN LOSS : 0.015089636164179234\n",
      "EPOCH 15 TRAIN LOSS : 0.014797103430416538\n",
      "EPOCH 16 TRAIN LOSS : 0.014493622759511984\n",
      "EPOCH 17 TRAIN LOSS : 0.01442087700626235\n",
      "EPOCH 18 TRAIN LOSS : 0.013671220556251022\n",
      "EPOCH 19 TRAIN LOSS : 0.013384997209252071\n",
      "EPOCH 20 TRAIN LOSS : 0.013659777671797697\n",
      "EPOCH 21 TRAIN LOSS : 0.012935150279673431\n",
      "EPOCH 22 TRAIN LOSS : 0.012510468202359133\n",
      "EPOCH 23 TRAIN LOSS : 0.011871099789767886\n",
      "EPOCH 24 TRAIN LOSS : 0.012316641522877252\n",
      "EPOCH 25 TRAIN LOSS : 0.011975416877884854\n",
      "EPOCH 26 TRAIN LOSS : 0.011489108744968992\n",
      "EPOCH 27 TRAIN LOSS : 0.012177404373693568\n",
      "EPOCH 28 TRAIN LOSS : 0.011533764633796871\n",
      "EPOCH 29 TRAIN LOSS : 0.011268532288862444\n",
      "EPOCH 30 TRAIN LOSS : 0.011617050686878945\n",
      "EPOCH 31 TRAIN LOSS : 0.011221772127314162\n",
      "EPOCH 32 TRAIN LOSS : 0.010851826749122473\n",
      "EPOCH 33 TRAIN LOSS : 0.011287051922222699\n",
      "EPOCH 34 TRAIN LOSS : 0.010469320804071324\n",
      "EPOCH 35 TRAIN LOSS : 0.011071383317650509\n",
      "EPOCH 36 TRAIN LOSS : 0.0108334181913689\n",
      "EPOCH 37 TRAIN LOSS : 0.010268088088615108\n",
      "EPOCH 38 TRAIN LOSS : 0.010813949204711263\n",
      "EPOCH 39 TRAIN LOSS : 0.010400379136172947\n",
      "EPOCH 40 TRAIN LOSS : 0.009653965738028097\n",
      "EPOCH 41 TRAIN LOSS : 0.009668079647682369\n",
      "EPOCH 42 TRAIN LOSS : 0.009933228431734194\n",
      "EPOCH 43 TRAIN LOSS : 0.009816991749094494\n",
      "EPOCH 44 TRAIN LOSS : 0.009293090814212238\n",
      "EPOCH 45 TRAIN LOSS : 0.010112230902287498\n",
      "EPOCH 46 TRAIN LOSS : 0.009936779546839343\n",
      "EPOCH 47 TRAIN LOSS : 0.010052516579882168\n",
      "EPOCH 48 TRAIN LOSS : 0.009938349855988264\n",
      "EPOCH 49 TRAIN LOSS : 0.009414522569062613\n",
      "EPOCH 50 TRAIN LOSS : 0.009599544409749859\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(50):\n",
    "    sum_losses = 0\n",
    "    for x, (images, labels) in enumerate(train_loader): \n",
    "        images = images.reshape(-1, 10*10)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(images)\n",
    "        losses = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step() \n",
    "        sum_losses += losses.item()\n",
    "        if x == 10:\n",
    "            break\n",
    "        \n",
    "    print(f\"EPOCH {epoch+1} TRAIN LOSS : {sum_losses / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6218a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "weights = model.linear.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55b39db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531fe0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1, 10, 10)\n",
      "(128, 100)\n",
      "(100, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "for i, (imgs, labels) in enumerate(train_loader):\n",
    "    imgs = imgs.to(device)\n",
    "    outputs = nn.Softmax(dim=1)(model(imgs))\n",
    "    imgs = imgs.detach().cpu().numpy()\n",
    "    \n",
    "    imgs2 = imgs.reshape((128, 100))\n",
    "    \n",
    "    w = (imgs2[:, np.newaxis, :] * weights[np.newaxis, :, :]).transpose(2, 1, 0)\n",
    "    w = np.maximum(w, 0)\n",
    "    w = np.minimum(w, 1)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    imgs = np.squeeze(imgs, axis=1).transpose(1, 2, 0)\n",
    "    outputs = np.expand_dims(outputs, axis=1).transpose(1, 2, 0)\n",
    "    np.save(\"inputs.npy\", imgs)\n",
    "    np.save(\"outputs.npy\", outputs)\n",
    "    np.save(\"weights.npy\", w)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
